{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3be0213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"FineTuning.ipynb\n",
    "\n",
    "Automatically generated by Colab.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1Mu79JOf1fo9LxresdbXpnYxoUJbjpa-R\n",
    "\"\"\"\n",
    "\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Read the content of skincare.txt\n",
    "with open('skincare.txt', 'r', encoding='utf-8') as file:\n",
    "    content = file.read()\n",
    "print(content[:500])  # preview first 500 characters\n",
    "\n",
    "!pip install transformers torch accelerate sentencepiece --quiet\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    \"google/flan-t5-base\",\n",
    "    torch_dtype=torch.bfloat16 if device == \"cuda\" else torch.float32,\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "def extract_keywords(text, max_keywords=15):\n",
    "    prompt = (f\"Extract exactly {max_keywords} distinct keywords or key phrases from the following text:\\n\\n{text}\\n\\nKeywords:\")\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "    print(\"Tokenizer input keys:\", inputs.keys())\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_length=200,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_k=60,\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1.2,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    keywords = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    keywords_list = [kw.strip() for kw in keywords.split(\",\") if kw.strip()]\n",
    "    return keywords_list\n",
    "\n",
    "\n",
    "# Test\n",
    "keywords = extract_keywords(content, max_keywords=15)\n",
    "print(\"Extracted Keywords:\", keywords)\n",
    "\n",
    "!pip install transformers datasets torch accelerate\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from datasets import load_dataset\n",
    "\n",
    "from google.colab import files\n",
    "uploaded = files.upload()  # Upload skincare_keywords_dataset.jsonl manually\n",
    "\n",
    "from datasets import load_dataset\n",
    "# load the dataset from your uploaded file\n",
    "dataset = load_dataset('json', data_files='skincare.jsonl', split='train')\n",
    "# split dataset into train and validation sets\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "model_name = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, device_map='auto', torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32)\n",
    "\n",
    "max_input_length = 256\n",
    "max_output_length = 64\n",
    "def preprocess(examples):\n",
    "    inputs = [\"Extract keywords: \" + text for text in examples['text']]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "    labels = tokenizer(examples['keywords'], max_length=max_output_length, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "tokenized_dataset = dataset.map(preprocess, batched=True)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./flan-t5-keywords\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=5,\n",
    "    predict_with_generate=True,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(\"./flan-t5-keywords-finetuned\")\n",
    "\n",
    "from transformers import pipeline\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./flan-t5-keywords-finetuned\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./flan-t5-keywords-finetuned\")\n",
    "keyword_extractor = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "# Extract filename from uploaded file\n",
    "filename = list(uploaded.keys())[0]\n",
    "# Read the file content\n",
    "with open(filename, \"r\") as file:\n",
    "    text = file.read()\n",
    "# Run inference with the loaded text\n",
    "result = keyword_extractor(f\"Extract keywords: {text}\", max_length=64)\n",
    "print(\"Extracted Keywords:\", result[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
